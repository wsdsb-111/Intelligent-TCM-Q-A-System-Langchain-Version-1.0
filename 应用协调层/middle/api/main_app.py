"""
LangChainä¸­é—´å±‚ä¸»åº”ç”¨
é›†æˆRAGé—®ç­”æœåŠ¡çš„FastAPIåº”ç”¨
å‚ç…§è¯„ä¼°ç³»ç»Ÿçš„ç»„ä»¶åŠ è½½æ–¹å¼è¿›è¡Œä¼˜åŒ–
"""

import time
import uuid
from contextlib import asynccontextmanager
from typing import Optional, Dict, Any
import sys
import os
import yaml
from enum import Enum
from dataclasses import dataclass

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
# main_app.pyåœ¨: åº”ç”¨åè°ƒå±‚/middle/api/
# å‘ä¸Šä¸¤çº§åˆ°è¾¾: åº”ç”¨åè°ƒå±‚/
middle_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
application_layer = os.path.dirname(middle_dir)  # åº”ç”¨åè°ƒå±‚
# å‘ä¸Šä¸€çº§åˆ°è¾¾é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(application_layer)
# é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•
config_dir = os.path.join(middle_dir, "config")
sys.path.insert(0, middle_dir)
sys.path.insert(0, project_root)

from middle.utils.logging_utils import get_logger
from middle.api.v1_routes import router as v1_router, init_routes
from middle.api.routes.dify_nodes import router as dify_router, init_dify_routes
from middle.api.routes.openai_compatible import router as openai_router
from middle.services.model_service import get_model_service
from middle.services.rag_chain import RAGChain
from middle.core.retrieval_coordinator import HybridRetrievalCoordinator
# BM25é€‚é…å™¨å·²ç§»é™¤
from middle.adapters.simple_vector_adapter import SimpleVectorAdapter
from middle.adapters.graph_adapter import GraphRetrievalAdapter

logger = get_logger(__name__)

# ========== å‚ç…§è¯„ä¼°ç³»ç»Ÿçš„ç»„ä»¶çŠ¶æ€ç®¡ç† ==========

class ComponentState(Enum):
    """ç»„ä»¶çŠ¶æ€æšä¸¾"""
    UNLOADED = "unloaded"
    LOADING = "loading"
    LOADED = "loaded"
    UNLOADING = "unloading"

@dataclass
class ComponentStatus:
    """ç»„ä»¶çŠ¶æ€ç®¡ç†"""
    state: ComponentState = ComponentState.UNLOADED
    load_time: Optional[float] = None
    unload_time: Optional[float] = None
    last_error: Optional[str] = None

# å…¨å±€å˜é‡ - ä¿æŒåŒæ­¥åŠ è½½æ–¹å¼
_app_start_time = time.time()
_model_service = None
_rag_chain = None
_retrieval_coordinator = None

# ç»„ä»¶çŠ¶æ€è·Ÿè¸ª
_component_status = {
    'model_service': ComponentStatus(),
    'retrieval_coordinator': ComponentStatus(),
    'vector_adapter': ComponentStatus(),
    'graph_adapter': ComponentStatus(),
    'rag_chain': ComponentStatus()
}


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç† - å‚ç…§è¯„ä¼°ç³»ç»Ÿçš„ç»“æ„åŒ–ç»„ä»¶åˆå§‹åŒ–"""
    global _model_service, _rag_chain, _retrieval_coordinator

    # å¯åŠ¨æ—¶æ‰§è¡Œ
    logger.info("=" * 80)
    logger.info("ğŸš€ LangChainä¸­é—´å±‚æœåŠ¡å¯åŠ¨ä¸­...")
    logger.info("=" * 80)

    try:
        # 0. åˆå§‹åŒ–ç»„ä»¶çŠ¶æ€
        _init_component_status()

        # 1. åŠ è½½é…ç½®
        config = _load_config()
        if not config:
            raise RuntimeError("é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥")

        # 2. åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ï¼ˆå‚ç…§è¯„ä¼°ç³»ç»Ÿçš„ç»“æ„åŒ–æ–¹å¼ï¼‰
        # è¾…åŠ©å‡½æ•°ï¼šè§£æç›¸å¯¹è·¯å¾„
        def resolve_path(relative_path: str) -> str:
            """è§£æç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„"""
            if not relative_path or os.path.isabs(relative_path):
                return relative_path
            return os.path.abspath(os.path.join(config_dir, relative_path))

        # 1. åˆå§‹åŒ–å‘é‡é€‚é…å™¨
        logger.info("[1/5] åˆå§‹åŒ–å‘é‡é€‚é…å™¨...")
        _component_status['vector_adapter'].state = ComponentState.LOADING
        start_time = time.time()

        vector_config = config.get('retrieval', {}).get('vector', {})
        vector_persist_dir = vector_config.get('persist_directory', "faiss_rag/å‘é‡æ•°æ®åº“_768ç»´")

        # å¤„ç†model_pathï¼š
        # - ç»å¯¹è·¯å¾„ï¼šç›´æ¥ä½¿ç”¨
        # - HFæ¨¡å‹æ ‡è¯†ï¼ˆå¦‚ "iic/nlp_gte_sentence-embedding_chinese-base"ï¼‰ï¼šä¿æŒåŸæ ·ï¼Œä¸åšè·¯å¾„è§£æ
        # - å…¶ä»–ç›¸å¯¹è·¯å¾„ï¼šè§£æä¸ºç»å¯¹è·¯å¾„
        model_path = vector_config.get('model_path')
        def _looks_like_hf_repo_id(p: str) -> bool:
            # ç»éªŒåˆ¤æ–­ï¼šåŒ…å«å•æ–œæ ã€ä¸æ˜¯ç»å¯¹è·¯å¾„ã€æœ¬åœ°ä¸å­˜åœ¨è¯¥è·¯å¾„
            try:
                return (
                    isinstance(p, str)
                    and '/' in p
                    and '\\' not in p
                    and not os.path.isabs(p)
                    and not os.path.exists(p)
                )
            except Exception:
                return False

        if model_path:
            if os.path.isabs(model_path):
                pass
            elif _looks_like_hf_repo_id(model_path):
                logger.info(f"æ£€æµ‹åˆ°HFæ¨¡å‹æ ‡è¯†ï¼ŒæŒ‰åç§°åŠ è½½: {model_path}")
            else:
                model_path = resolve_path(model_path)

        # å¦‚æœæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´ï¼Œå›é€€åˆ°é€‚é…å™¨å†…ç½®é»˜è®¤æ¨¡å‹è·¯å¾„ï¼ˆä¸è¯„ä¼°å™¨ä¸€è‡´ï¼‰
        try:
            if model_path and not os.path.exists(model_path):
                logger.warning(f"å‘é‡æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œå›é€€åˆ°é»˜è®¤: {model_path}")
                model_path = None
            else:
                # è‹¥ç¼ºå°‘æ ¸å¿ƒæ–‡ä»¶ï¼ˆå¦‚config.jsonï¼‰ï¼Œä¹Ÿå›é€€
                if model_path:
                    cfg_file = os.path.join(model_path, 'config.json')
                    if not os.path.exists(cfg_file):
                        logger.warning(f"æ¨¡å‹ç›®å½•ç¼ºå°‘config.jsonï¼Œå›é€€åˆ°é»˜è®¤: {model_path}")
                        model_path = None
        except Exception as _:
            model_path = None

        resolved_persist_dir = resolve_path(vector_persist_dir)
        if not os.path.exists(resolved_persist_dir):
            logger.warning(f"å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨ï¼š{resolved_persist_dir}ï¼Œè¯·ç¡®è®¤å·²æ„å»ºFAISSç´¢å¼•ä¸documents.json")

        # å…³é”®è¯åº“è·¯å¾„ä¼˜å…ˆå¤ç”¨æ™ºèƒ½è·¯ç”±å®ä½“CSVï¼Œæå‡å¬å›ï¼ˆä¸è¯„ä¼°å™¨ä¸€è‡´ï¼‰
        intelligent_router_cfg = config.get('retrieval', {}).get('intelligent_router', {})
        keyword_csv_path = intelligent_router_cfg.get('entity_csv_path')
        if keyword_csv_path and not os.path.isabs(keyword_csv_path):
            keyword_csv_path = resolve_path(keyword_csv_path)

        vector_adapter = SimpleVectorAdapter(
            persist_directory=resolved_persist_dir,
            model_path=model_path,
            timeout=vector_config.get('timeout', 60),
            score_threshold=vector_config.get('score_threshold', 0.0),
            enable_keyword_enhancement=False,  # å·²ç§»é™¤å…³é”®è¯å¢å¼ºåŠŸèƒ½
            keyword_csv_path=keyword_csv_path  # ä¿ç•™å‚æ•°ä»¥é¿å…åˆå§‹åŒ–é”™è¯¯ï¼Œä½†ä¸ä¼šä½¿ç”¨
        )

        _component_status['vector_adapter'].state = ComponentState.LOADED
        _component_status['vector_adapter'].load_time = time.time() - start_time
        logger.info(f"   âœ“ å‘é‡é€‚é…å™¨åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {_component_status['vector_adapter'].load_time:.2f}ç§’")

        # 2. åˆå§‹åŒ–æ¨¡å‹æœåŠ¡
        logger.info("[2/5] åˆå§‹åŒ–æ¨¡å‹æœåŠ¡...")
        _component_status['model_service'].state = ComponentState.LOADING
        start_time = time.time()

        _model_service = get_model_service()

        # ä»é…ç½®è¯»å–æ¨¡å‹è·¯å¾„
        base_model_path = config['model']['base_model_path']
        adapter_path = config['model']['adapter_path']

        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºé…ç½®æ–‡ä»¶ç›®å½•ï¼‰
        if not os.path.isabs(base_model_path):
            base_model_path = os.path.abspath(os.path.join(config_dir, base_model_path))
        if not os.path.isabs(adapter_path):
            adapter_path = os.path.abspath(os.path.join(config_dir, adapter_path))

        # è®¾å¤‡ä»é…ç½®è¯»å–ï¼Œä¼˜å…ˆä½¿ç”¨GPU
        model_device = config.get('model', {}).get('device', 'auto')
        logger.info(f"æ¨¡å‹åŠ è½½ç›®æ ‡è®¾å¤‡: {model_device}")
        success = _model_service.load_model(
            base_model_path=base_model_path,
            adapter_path=adapter_path,
            device=model_device
        )

        if success:
            _component_status['model_service'].state = ComponentState.LOADED
            _component_status['model_service'].load_time = time.time() - start_time
            logger.info(f"   âœ“ æ¨¡å‹æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {_component_status['model_service'].load_time:.2f}ç§’")
        else:
            _component_status['model_service'].state = ComponentState.UNLOADED
            _component_status['model_service'].last_error = "æ¨¡å‹åŠ è½½å¤±è´¥"
            logger.error("   âœ— æ¨¡å‹åŠ è½½å¤±è´¥")
            raise RuntimeError("æ¨¡å‹åŠ è½½å¤±è´¥")

        # 3. åˆå§‹åŒ–å›¾æ£€ç´¢é€‚é…å™¨
        logger.info("[3/5] åˆå§‹åŒ–å›¾æ£€ç´¢é€‚é…å™¨...")
        _component_status['graph_adapter'].state = ComponentState.LOADING
        start_time = time.time()

        graph_config = config.get('retrieval', {}).get('graph', {})
        graph_adapter = GraphRetrievalAdapter(
            neo4j_uri=graph_config.get('neo4j_uri', "neo4j://127.0.0.1:7687"),
            username=graph_config.get('username', "neo4j"),
            password=graph_config.get('password', "hx1230047"),
            database=graph_config.get('database', "neo4j"),
            timeout=graph_config.get('timeout', 20),
            model_service=_model_service,
            use_llm_entity_extraction=graph_config.get('use_llm_entity_extraction', False)
        )

        _component_status['graph_adapter'].state = ComponentState.LOADED
        _component_status['graph_adapter'].load_time = time.time() - start_time
        logger.info(f"   âœ“ å›¾æ£€ç´¢é€‚é…å™¨åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {_component_status['graph_adapter'].load_time:.2f}ç§’")

        # 4. åˆå§‹åŒ–æ£€ç´¢åè°ƒå™¨
        logger.info("[4/5] åˆå§‹åŒ–æ£€ç´¢åè°ƒå™¨...")
        _component_status['retrieval_coordinator'].state = ComponentState.LOADING
        start_time = time.time()

        # è·å–æ™ºèƒ½è·¯ç”±å™¨é…ç½®
        intelligent_router_config = config.get('retrieval', {}).get('intelligent_router', {})

        _retrieval_coordinator = HybridRetrievalCoordinator(
            vector_adapter=vector_adapter,
            graph_adapter=graph_adapter,
            use_intelligent_routing=True,  # å¯ç”¨æ™ºèƒ½è·¯ç”±
            intelligent_router_config=intelligent_router_config
        )

        _component_status['retrieval_coordinator'].state = ComponentState.LOADED
        _component_status['retrieval_coordinator'].load_time = time.time() - start_time
        logger.info(f"   âœ“ æ£€ç´¢åè°ƒå™¨åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {_component_status['retrieval_coordinator'].load_time:.2f}ç§’")

        # 5. åˆå§‹åŒ–RAGé“¾è·¯
        logger.info("[5/5] åˆå§‹åŒ–RAGé“¾è·¯...")
        _component_status['rag_chain'].state = ComponentState.LOADING
        start_time = time.time()

        _rag_chain = RAGChain(
            retrieval_coordinator=_retrieval_coordinator,
            max_context_tokens=1500,
            max_retrieval_results=5
        )

        # åˆå§‹åŒ–è·¯ç”±ä¾èµ–
        init_routes(_rag_chain, _retrieval_coordinator)
        
        # åˆå§‹åŒ–DifyèŠ‚ç‚¹è·¯ç”±ä¾èµ–
        init_dify_routes(_rag_chain, _retrieval_coordinator)

        _component_status['rag_chain'].state = ComponentState.LOADED
        _component_status['rag_chain'].load_time = time.time() - start_time
        logger.info(f"   âœ“ RAGé“¾è·¯åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {_component_status['rag_chain'].load_time:.2f}ç§’")

        # 6. é¢„çƒ­æ£€ç´¢æ¨¡å—ï¼ˆå‚ç…§è¯„ä¼°ç³»ç»Ÿçš„é¢„çƒ­æ–¹å¼ï¼‰
        logger.info("[6/6] é¢„çƒ­æ£€ç´¢æ¨¡å—...")
        try:
            from middle.models.data_models import RetrievalConfig

            # é¢„çƒ­å‘é‡æ£€ç´¢
            logger.info("   é¢„çƒ­å‘é‡æ£€ç´¢...")
            warmup_config_vector = RetrievalConfig(
                enable_vector=True,
                enable_graph=False,
                top_k=10,  # å‚è€ƒè¯„ä¼°ç³»ç»Ÿï¼Œä½¿ç”¨æ›´å¤§çš„top_k
                timeout=60
            )
            warmup_results = await _retrieval_coordinator.retrieve("å¤´ç—›", warmup_config_vector)
            logger.info(f"   âœ“ å‘é‡æ£€ç´¢é¢„çƒ­å®Œæˆï¼ˆè¿”å›{len(warmup_results)}ä¸ªç»“æœï¼‰")

            # é¢„çƒ­å›¾æ£€ç´¢
            logger.info("   é¢„çƒ­å›¾æ£€ç´¢...")
            warmup_config_graph = RetrievalConfig(
                enable_vector=False,
                enable_graph=True,
                top_k=10,  # å‚è€ƒè¯„ä¼°ç³»ç»Ÿï¼Œä½¿ç”¨æ›´å¤§çš„top_k
                timeout=30
            )
            warmup_results = await _retrieval_coordinator.retrieve("äººå‚", warmup_config_graph)
            logger.info(f"   âœ“ å›¾æ£€ç´¢é¢„çƒ­å®Œæˆï¼ˆè¿”å›{len(warmup_results)}ä¸ªç»“æœï¼‰")

            logger.info("   âœ“ æ£€ç´¢æ¨¡å—é¢„çƒ­å®Œæˆ")
        except Exception as e:
            logger.warning(f"æ£€ç´¢æ¨¡å—é¢„çƒ­å¤±è´¥ï¼ˆä¸å½±å“æœåŠ¡è¿è¡Œï¼‰: {e}")

        logger.info("=" * 80)
        logger.info("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼ŒæœåŠ¡å¯åŠ¨æˆåŠŸ")
        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        raise

    yield

    # å…³é—­æ—¶æ‰§è¡Œ
    logger.info("ğŸ”„ æœåŠ¡å…³é—­ä¸­...")
    _cleanup_components()
    logger.info("âœ… æœåŠ¡å·²å…³é—­")


def _init_component_status():
    """åˆå§‹åŒ–ç»„ä»¶çŠ¶æ€"""
    global _component_status
    for component_name in _component_status:
        _component_status[component_name].state = ComponentState.UNLOADED
        _component_status[component_name].last_error = None


def _load_config() -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        config_path = os.path.join(os.path.dirname(__file__), "..", "config", "service_config.yaml")
        logger.info(f"ğŸ”„ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        logger.info("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        return config

    except Exception as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return {}





def _cleanup_components():
    """æ¸…ç†ç»„ä»¶"""
    global _model_service, _rag_chain, _retrieval_coordinator

    try:
        # æ¸…ç†ç»„ä»¶
        if _rag_chain:
            _rag_chain = None

        if _retrieval_coordinator:
            _retrieval_coordinator = None

        if _model_service:
            _model_service = None

        # æ›´æ–°ç»„ä»¶çŠ¶æ€
        for component_name in _component_status:
            _component_status[component_name].state = ComponentState.UNLOADED
            _component_status[component_name].unload_time = time.time()

    except Exception as e:
        logger.error(f"ç»„ä»¶æ¸…ç†å¤±è´¥: {e}")
    
    try:
        # å¸è½½æ¨¡å‹
        if _model_service:
            _model_service.unload_model()
            logger.info("   âœ“ æ¨¡å‹å·²å¸è½½")
        
        # æ¸…ç†å…¶ä»–èµ„æº
        logger.info("   âœ“ èµ„æºæ¸…ç†å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ èµ„æºæ¸…ç†å¤±è´¥: {e}", exc_info=True)
    
    logger.info("=" * 80)
    logger.info("ğŸ‘‹ LangChainä¸­é—´å±‚æœåŠ¡å·²å…³é—­")
    logger.info("=" * 80)


def create_app() -> FastAPI:
    """åˆ›å»ºFastAPIåº”ç”¨"""
    
    # åˆ›å»ºåº”ç”¨
    app = FastAPI(
        title="LangChainä¸­é—´å±‚API",
        description="""
        # æ™ºèƒ½ä¸­åŒ»é—®ç­”RAGç³»ç»ŸAPI
        
        ## åŠŸèƒ½ç‰¹ç‚¹
        
        - ğŸ” **æ··åˆæ£€ç´¢**: é›†æˆBM25ã€å‘é‡æ£€ç´¢ã€çŸ¥è¯†å›¾è°±ä¸‰ç§æ£€ç´¢æ–¹å¼
        - ğŸ¤– **æ™ºèƒ½ç”Ÿæˆ**: åŸºäºQwen1.5-1.8Bå¾®è°ƒæ¨¡å‹çš„ä¸­åŒ»é—®ç­”ç”Ÿæˆ
        - ğŸ¯ **RAGæ¶æ„**: æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œç¡®ä¿ç­”æ¡ˆå‡†ç¡®å¯é 
        - ğŸ“Š **å®Œæ•´API**: é—®ç­”ã€æ£€ç´¢ã€å¥åº·æ£€æŸ¥ç­‰å®Œæ•´æ¥å£
        - ğŸ”Œ **Difyå°±ç»ª**: é¢„ç•™æµå¼è¾“å‡ºå’Œå¤šæ¨¡æ€æ¥å£ï¼Œå¯æ— ç¼å¯¹æ¥Dify
        
        ## æ ¸å¿ƒæ¥å£
        
        - **POST /api/v1/query**: é—®ç­”æ¥å£ï¼Œè¿”å›ç”Ÿæˆçš„ç­”æ¡ˆå’Œæ£€ç´¢ç»“æœ
        - **POST /api/v1/retrieve**: çº¯æ£€ç´¢æ¥å£ï¼Œä»…è¿”å›æ£€ç´¢ç»“æœ
        - **GET /api/v1/health**: å¥åº·æ£€æŸ¥ï¼ŒæŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
        - **POST /api/v1/multimodal**: å¤šæ¨¡æ€æ¥å£ï¼ˆé¢„ç•™ï¼‰
        
        ## ä½¿ç”¨ç¤ºä¾‹
        
        ```python
        import requests
        
        # é—®ç­”ç¤ºä¾‹
        response = requests.post("http://localhost:8000/api/v1/query", json={
            "query": "å¤´ç—›æ€ä¹ˆæ²»ç–—",
            "top_k": 5,
            "temperature": 0.7
        })
        
        result = response.json()
        print(result["answer"])
        ```
        
        ## æŠ€æœ¯æ ˆ
        
        - **æ£€ç´¢**: BM25 + ChromaDB + Neo4j
        - **æ¨¡å‹**: Qwen1.5-1.8B + LoRAå¾®è°ƒ
        - **æ¡†æ¶**: FastAPI + LangChain
        - **èåˆ**: RRF (Reciprocal Rank Fusion)
        """,
        version="1.0.0",
        lifespan=lifespan,
        docs_url="/docs",
        redoc_url="/redoc",
        openapi_url="/openapi.json"
    )
    
    # CORSé…ç½®
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # è¯·æ±‚å¤„ç†ä¸­é—´ä»¶
    @app.middleware("http")
    async def process_request(request: Request, call_next):
        """è¯·æ±‚å¤„ç†å’Œæ—¥å¿—ä¸­é—´ä»¶"""
        start_time = time.time()
        request_id = str(uuid.uuid4())
        
        # è®°å½•è¯·æ±‚
        logger.info(f"[{request_id}] {request.method} {request.url.path}")
        
        try:
            response = await call_next(request)
            
            # æ·»åŠ å“åº”å¤´
            process_time = time.time() - start_time
            response.headers["X-Request-ID"] = request_id
            response.headers["X-Process-Time"] = f"{process_time:.3f}"
            
            logger.info(f"[{request_id}] å®Œæˆ {response.status_code} ({process_time:.3f}s)")
            
            return response
            
        except Exception as e:
            process_time = time.time() - start_time
            logger.error(f"[{request_id}] é”™è¯¯: {e} ({process_time:.3f}s)", exc_info=True)
            
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "error": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}",
                    "request_id": request_id
                },
                headers={"X-Request-ID": request_id}
            )
    
    # å¼‚å¸¸å¤„ç†
    @app.exception_handler(StarletteHTTPException)
    async def http_exception_handler(request: Request, exc: StarletteHTTPException):
        """HTTPå¼‚å¸¸å¤„ç†"""
        return JSONResponse(
            status_code=exc.status_code,
            content={
                "success": False,
                "error": exc.detail
            }
        )
    
    @app.exception_handler(RequestValidationError)
    async def validation_exception_handler(request: Request, exc: RequestValidationError):
        """è¯·æ±‚éªŒè¯å¼‚å¸¸å¤„ç†"""
        return JSONResponse(
            status_code=422,
            content={
                "success": False,
                "error": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
                "detail": exc.errors()
            }
        )
    
    # æ³¨å†Œè·¯ç”±
    app.include_router(v1_router)
    
    # æ³¨å†ŒDifyèŠ‚ç‚¹è·¯ç”±
    app.include_router(dify_router)
    logger.info("âœ… DifyèŠ‚ç‚¹è·¯ç”±å·²æ³¨å†Œ: /api/dify/*")
    
    # æ³¨å†ŒOpenAIå…¼å®¹è·¯ç”±
    app.include_router(openai_router)
    logger.info("âœ… OpenAIå…¼å®¹APIå·²æ³¨å†Œ: /v1/chat/completions")
    logger.info(f"âœ… API Key: {os.getenv('OPENAI_API_KEY', 'sk-qwen3-1.7b-local-dev-key-12345')}")
    logger.info("âœ… API Base: http://localhost:8000/v1/chat/completions")
    
    # æ ¹è·¯å¾„
    @app.get("/", tags=["root"])
    async def root():
        """æ ¹è·¯å¾„"""
        uptime = int(time.time() - _app_start_time)
        return {
            "service": "LangChainä¸­é—´å±‚API",
            "version": "1.0.0",
            "status": "running",
            "uptime_seconds": uptime,
            "docs": "/docs",
            "health": "/api/v1/health",
            "timestamp": time.time()
        }
    
    logger.info("âœ… FastAPIåº”ç”¨åˆ›å»ºå®Œæˆ")
    return app


# åˆ›å»ºåº”ç”¨å®ä¾‹
app = create_app()


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "main_app:app",
        host="0.0.0.0",
        port=8000,
        reload=False,  # ç”Ÿäº§ç¯å¢ƒè®¾ä¸ºFalse
        log_level="info"
    )

